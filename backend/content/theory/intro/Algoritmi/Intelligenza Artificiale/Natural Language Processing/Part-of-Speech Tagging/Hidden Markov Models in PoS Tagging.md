# Hidden Markov Models in PoS Tagging

A partire dagli anni '70, il **PoS tagging** ha iniziato a essere affrontato anche con **metodi probabilistici**, cio√® **stocastici**.

L'idea alla base √® semplice: usare i **modelli di Markov nascosti (HMM)** per selezionare la **sequenza di etichette grammaticale pi√π probabile** data una sequenza di parole.

Formalmente, il problema pu√≤ essere formulato come segue:

$$
\hat{t}_1^n = \underset{t_1^n \in \text{Tagset}^n}{\arg\max} \ P(t_1^n \mid w_1^n)
$$

In altre parole, cerchiamo la sequenza di tag $t_1^n$ che **massimizza la probabilit√† condizionata** dato l'input $w_1^n$, ovvero la sequenza di parole osservate.

## Teorema di Bayes

Per calcolare questa probabilit√†, possiamo ricorrere al **teorema di Bayes**:

$$
P(x \mid y) = \frac{P(y \mid x) \cdot P(x)}{P(y)}
$$

Applicandolo al nostro problema:

$$
P(t_1^n \mid w_1^n) = \frac{P(w_1^n \mid t_1^n) \cdot P(t_1^n)}{P(w_1^n)}
$$

Poich√© $P(w_1^n)$ √® costante rispetto ai tag $t_1^n$, possiamo ignorarlo nel calcolo dell'$\arg\max$. Otteniamo quindi:

$$
\hat{t}_1^n = \underset{t_1^n \in \text{Tagset}^n}{\arg\max} \ \frac{P(w_1^n \mid t_1^n) \cdot P(t_1^n)}{P(w_1^n)} \approx \underset{t_1^n \in \text{Tagset}^n}{\arg\max} P(w_1^n \mid t_1^n) \cdot P(t_1^n)
$$

Dove:
- $P(w_1^n \mid t_1^n)$ √® la **verosimiglianza** (*likelihood*): probabilit√† di osservare le parole date le etichette.
- $P(t_1^n)$ √® la **probabilit√† a priori** (*prior*) delle etichette grammaticali.

In pratica, cerchiamo la sequenza di PoS tag che **spiega meglio le parole osservate**, tenendo anche conto di quanto sia **probabile a priori** quella sequenza di tag. Ma come calcolare queste probabilit√†?

## Assunzione 1: La parola dipende solo dal suo PoS tag

Per semplificare il calcolo della **verosimiglianza** $P(w_1^n \mid t_1^n)$, si fa la seguente assunzione:

> Ogni parola $w_i$ dipende solo dal suo corrispondente tag $t_i$.

Formalmente:

$$
P(w_1^n \mid t_1^n) = \prod_{i=1}^{n} P(w_i \mid t_i)
$$

Questa √® un‚Äô**assunzione di indipendenza condizionata**: ci permette di calcolare la probabilit√† delle parole in modo **locale**, tag per tag, invece che sull'intera sequenza.

## Assunzione 2: Ogni tag dipende solo dal tag precedente

Per semplificare il calcolo della **prior** $P(t_1^n)$, si assume che ogni tag dipenda **solo dal tag precedente**:

> Questo √® noto come **bigram model** o **Markov assumption di primo ordine**.

Formalmente:

$$
P(t_1^n) = \prod_{i=1}^{n} P(t_i \mid t_{i-1})
$$

Questo significa che la sequenza dei tag viene modellata come una **catena di Markov**: non consideriamo tutta la storia passata dei tag, ma solo quello immediatamente precedente.

## Combinazione delle due assunzioni

Applicando insieme le due assunzioni precedenti otteniamo:

$$
P(w_1^n \mid t_1^n) \cdot P(t_1^n) = \prod_{i=1}^{n} P(w_i \mid t_i) \cdot P(t_i \mid t_{i-1})
$$

Questo prodotto √® il cuore del PoS tagging stocastico: stimiamo la **probabilit√† congiunta** della sequenza parole-tag usando stime locali.

## Stima delle probabilit√† dai corpora

Grazie a **corpora annotati** (es. Penn Treebank, Universal Dependencies), possiamo stimare le due componenti:

- **Probabilit√† di emissione** (likelihood):  
  $$
  P(w_i \mid t_i) = \frac{\text{conteggio}(t_i, w_i)}{\text{conteggio}(t_i)}
  $$

- **Probabilit√† di transizione** (prior):  
  $$
  P(t_i \mid t_{i-1}) = \frac{\text{conteggio}(t_{i-1}, t_i)}{\text{conteggio}(t_{i-1})}
  $$

Queste stime si basano sulla **frequenza relativa** osservata nei corpus PoS-annotati.

## Come trovare la sequenza di tag ottimale?

Ora abbiamo:
- le probabilit√† $P(w_i \mid t_i)$ ‚Üí emissione
- le probabilit√† $P(t_i \mid t_{i-1})$ ‚Üí transizione

Ma dobbiamo trovare la **sequenza di tag $\hat{t}_1^n$** che **massimizza il prodotto** di questi termini.

Questo √® un problema classico di **decodifica in modelli di Markov nascosti**.

## Utilizzo degli Hidden Markov Models

Per risolvere il problema del PoS tagging ‚Äî ovvero associare la sequenza di parole a una sequenza di tag grammaticale ‚Äî si pu√≤ modellare il processo come un **Hidden Markov Model (HMM)**.

Un HMM √® un modello statistico in cui:
- Esiste una **sequenza nascosta di stati** (nel nostro caso, i **tag** grammaticali).
- Ogni stato emette un'**osservazione** (nel nostro caso, una **parola** del testo).
- Le transizioni tra stati e le emissioni sono regolate da **probabilit√†**.

**Formalmente**:

- $Q = q_1 q_2 \dots q_N$  **un insieme di $N$ stati**

- $A = a_{11} \dots a_{ij} \dots a_{NN}$ **una matrice di probabilit√† di transizione** $A$, dove ogni $a_{ij}$ rappresenta la probabilit√†  
  di passare dallo stato $i$ allo stato $j$, tale che $\sum_{j=1}^N a_{ij} = 1 \quad \forall i$

- $O = o_1 o_2 \dots o_T$ **una sequenza di $T$ osservazioni**, ciascuna presa da un vocabolario $V = v_1, v_2, \dots, v_V$

- $B = b_i(o_t)$ **una sequenza di probabilit√† di osservazione**, dette anche **probabilit√† di emissione**, ognuna delle quali esprime la probabilit√† che un'osservazione $o_t$ venga generata dallo stato $q_i$

- $\pi = \pi_1, \pi_2, \dots, \pi_N$ **una distribuzione di probabilit√† iniziale** sugli stati. $\pi_i$ √® la probabilit√† che la catena di Markov inizi nello stato $i$. Alcuni stati $j$ possono avere $\pi_j = 0$,  
  cio√® non possono essere stati iniziali. Inoltre, $\sum_{i=1}^n \pi_i = 1$

### Due assunzioni fondamentali di un HMM di primo ordine

1. **Assunzione di Markov**:  
   Ogni stato (tag) dipende solo dallo **stato precedente**:
   $$
   P(t_i \mid t_1^{i-1}) \approx P(t_i \mid t_{i-1})
   $$

2. **Assunzione di emissione indipendente**:  
   Ogni parola dipende solo dal **tag corrente**, non dagli altri tag o parole:
   $$
   P(w_i \mid t_1^n, w_1^{i-1}) \approx P(w_i \mid t_i)
   $$

Applicando queste due assunzioni otteniamo la formula:
$$
\hat{t}_1^n = \arg\max_{t_1^n \in Tagset^n} \prod_{i=1}^n P(w_i \mid t_i) \cdot P(t_i \mid t_{i-1})
$$

[[Hidden Markov Models|Qui]] √® diposnibile una descrizione dettagliata degli HMM.

### Esempio: Jason Eisner task (2002)

Un esempio classico per spiegare gli HMM √® il **"Jason Eisner task"**:

> Jason tiene un diario con il numero di gelati mangiati ogni giorno dell'estate.
> Il suo obiettivo √® ricostruire, a partire da questi numeri, se ogni giorno era caldo (**H**) o freddo (**C**).

Formalmente:
- La sequenza **osservata** $O$ √® il numero di gelati mangiati ogni giorno.
- La sequenza **nascosta** $Q$ √® la condizione meteorologica (**H**ot o **C**old).
- Ogni giorno Jason sceglie quanti gelati mangiare **in base al meteo**.
- L‚Äôobiettivo √® **inferire la sequenza di stati** che ha prodotto le osservazioni.

Questo √® del tutto analogo al PoS tagging:
- Le **osservazioni** sono le parole del testo.
- Gli **stati nascosti** sono i tag grammaticali.
- L‚Äôobiettivo √® inferire la **sequenza di tag pi√π probabile** dato il testo osservato.

### Riassunto dei componenti di un HMM per il PoS tagging

| Componente | Significato NLP | Simbolo | Come si calcola |
|------------|------------------|---------|------------------|
| Stati $Q$ | Tag PoS | $t_i$ | Predefiniti nel tagset |
| Osservazioni $O$ | Parole del testo | $w_i$ | Input della frase |
| Transizione | $P(t_i \mid t_{i-1})$ | Tag ‚Üí Tag | Frequenze nei corpora |
| Emissione | $P(w_i \mid t_i)$ | Tag ‚Üí Parola | Frequenze nei corpora |
| Iniziale $\pi(t_1)$ | Probabilit√† iniziale di ogni tag | $P(t_1)$ | Conta quanti tag iniziali in corpus |

### Obiettivo finale

Data una frase (sequenza di parole), vogliamo trovare:

$$
\hat{t}_1^n = \arg\max_{t_1^n} P(w_1^n \mid t_1^n) \cdot P(t_1^n)
$$

Dove $P(w_1^n \mid t_1^n)$ e $P(t_1^n)$ sono le **verosimiglianze** e **probabilit√† a priori**.


### Esempio pratico


Supponiamo di avere il seguente **corpus annotato** (PoS-tagged):

```
the/DT dog/NN barks/VBZ
the/DT can/NN falls/VBZ
we/PRP can/MD win/VB
book/NN the/DT book/VB
dogs/NNS bark/VBP
cats/NNS sleep/VBP
the/DT can/MD run/VB
can/MD you/PRP run/VB
some/DT dogs/NNS bark/VBP
```

#### 1. Insieme dei tag e parole

- **Tag (Q)** = { `DT`, `PRP`, `NN`, `NNS`, `MD`, `VBZ`, `VBP`, `VB` }  
- **Parole (O)** = { the, some, we, you, dog, dogs, cat(s), can, book, bark, barks, falls, sleep, run, win }

#### 2. Probabilit√† di transizione

| Transizione           | Conteggio | Probabilit√† |
|-----------------------|-----------|-------------|
| ‚ü®s‚ü© ‚Üí DT              | 4         | 4/9 ‚âÉ 0.44  |
| ‚ü®s‚ü© ‚Üí PRP             | 1         | 1/9 ‚âÉ 0.11  |
| ‚ü®s‚ü© ‚Üí NN              | 1         | 1/9 ‚âÉ 0.11  |
| ‚ü®s‚ü© ‚Üí NNS             | 2         | 2/9 ‚âÉ 0.22  |
| ‚ü®s‚ü© ‚Üí MD              | 1         | 1/9 ‚âÉ 0.11  |
| DT ‚Üí NN               | 2         | 2/5 = 0.40  |
| DT ‚Üí MD               | 1         | 1/5 = 0.20  |
| DT ‚Üí NNS              | 1         | 1/5 = 0.20  |
| DT ‚Üí VB               | 1         | 1/5 = 0.20  |
| PRP ‚Üí MD              | 1         | 1/2 = 0.50  |
| PRP ‚Üí VB              | 1         | 1/2 = 0.50  |
| NN ‚Üí VBZ              | 2         | 2/3 ‚âÉ 0.67  |
| NN ‚Üí DT               | 1         | 1/3 ‚âÉ 0.33  |
| NNS ‚Üí VBP             | 2         | 3/3 = 1.00  |
| MD ‚Üí VB               | 2         | 2/3 ‚âÉ 0.67  |
| MD ‚Üí PRP              | 1         | 1/3 ‚âÉ 0.33  |

#### 3. Probabilit√† di emissione

**DT** (5 occorrenze)

| Parola | Conteggio | Probabilit√† |
|--------|-----------|-------------|
| the    | 4         | 4/5 = 0.80  |
| some   | 1         | 1/5 = 0.20  |

**PRP** (2 occorrenze)

| Parola | Conteggio | Probabilit√† |
|--------|-----------|-------------|
| we     | 1         | 1/2 = 0.50  |
| you    | 1         | 1/2 = 0.50  |

**NN** (4 occorrenze)

| Parola | Conteggio | Probabilit√† |
|--------|-----------|-------------|
| dog    | 1         | 1/3 ‚âà 0.333 |
| can    | 1         | 1/3 ‚âà 0.333 |
| book   | 1         | 1/3 ‚âà 0.333 |

**NNS** (3 occorrenze)

| Parola | Conteggio | Probabilit√† |
|--------|-----------|-------------|
| dogs   | 2         | 2/3 ‚âÉ 0.67  |
| cats   | 1         | 1/3 ‚âÉ 0.33  |

**MD** (3 occorrenze)

| Parola | Conteggio | Probabilit√† |
|--------|-----------|-------------|
| can    | 3         | 3/3 = 1.00  |

**VBZ** (2 occorrenze)

| Parola | Conteggio | Probabilit√† |
|--------|-----------|-------------|
| barks  | 1         | 1/2 = 0.50  |
| falls  | 1         | 1/2 = 0.50  |

**VBP** (2 occorrenze)

| Parola | Conteggio | Probabilit√† |
|--------|-----------|-------------|
| bark   | 2         | 2/3 ‚âà 0.667 |
| sleep  | 1         | 1/3 ‚âà 0.333 |

**VB** (4 occorrenze)

| Parola | Conteggio | Probabilit√† |
|--------|-----------|-------------|
| win    | 1         | 1/4 = 0.25  |
| book   | 1         | 1/4 = 0.25  |
| run    | 2         | 2/4 = 0.50  |

#### 4. Rappresentazione TikZ del modello HMM

```tikz
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, shapes.multipart}

\begin{document}
\begin{tikzpicture}[
  ->, 
  >=Stealth, 
  every node/.style={font=\scriptsize},
  state/.style={circle, draw, minimum size=1cm},
  box/.style={rectangle, draw, fill=blue!10, align=left, minimum width=2cm},
  node distance=3cm and 3.5cm
]
  % Stati - prima riga
  \node[state] (START) {$\langle s\rangle$};
  \node[state, right=of START] (DT) {DT};
  \node[state, right=of DT] (NN) {NN};
  \node[state, right=of NN] (VBZ) {VBZ};
  
  % Stati - seconda riga
  \node[state, below=4cm of START] (PRP) {PRP};
  \node[state, right=of PRP] (NNS) {NNS};
  \node[state, right=of NNS] (VBP) {VBP};
  
  % Stati - terza riga
  \node[state, below=4cm of PRP] (MD) {MD};
  \node[state, right=of MD] (VB) {VB};
  
  % Transizioni da START
  \path (START) edge node[above] {4/9} (DT);
  \path (START) edge node[left] {1/9} (PRP);
  \path (START) edge[bend left=30] node[above, pos=0.7] {1/9} (NN);
  \path (START) edge[bend right=25] node[right,pos=0.3] {2/9} (NNS);
  \path (START) edge[bend right=40] node[left, pos=0.7] {1/9} (MD);
  
  % Transizioni interne - prima riga
  \path (DT) edge node[above] {2/5} (NN);
  \path (NN) edge node[above] {2/3} (VBZ);
  \path (NN) edge[bend right=40] node[above, pos=0.2] {1/3} (DT);
  
  % Transizioni interne - seconda riga
  \path (NNS) edge node[above] {1.0} (VBP);
  
  % Transizioni interne - attraversamenti tra righe
  \path (DT) edge[bend right=25] node[right, pos=0.2] {1/5} (MD);
  \path (DT) edge[bend right=20] node[right, pos=0.3] {1/5} (NNS);
  \path (DT) edge[bend right=30] node[right, pos=0.5] {1/5} (VB);
  
  \path (PRP) edge[bend left=15] node[right, pos=0.3] {1/2} (MD);
  \path (PRP) edge[bend right=40] node[left, pos=0.7] {1/2} (VB);
  
  \path (MD) edge node[above] {2/3} (VB);
  \path (MD) edge[bend right=60] node[right] {1/3} (PRP);
  
  % Box emissioni - posizioni migliorate
  \node[box, above=1.5cm of DT] (B_DT) {
    $P(\text{the})=0.80$\\
    $P(\text{some})=0.20$
  };
  
  % Box emissioni NN
  \node[box, above=1.5cm of NN] (B_NN) {
    $P(\text{dog})=0.333$\\
    $P(\text{can})=0.333$\\
    $P(\text{book})=0.333$
  };
  
  \node[box, above=1.5cm of VBZ] (B_VBZ) {
    $P(\text{barks})=0.50$\\
    $P(\text{falls})=0.50$
  };
  
  \node[box, below=1.5cm of PRP] (B_PRP) {
    $P(\text{we})=0.50$\\
    $P(\text{you})=0.50$
  };
  
  \node[box, below=1.5cm of NNS] (B_NNS) {
    $P(\text{dogs})=0.67$\\
    $P(\text{cats})=0.33$
  };
  
  % Box emissioni VBP
  \node[box, below=1.5cm of VBP] (B_VBP) {
    $P(\text{bark})=0.667$\\
    $P(\text{sleep})=0.333$
  };
  
  \node[box, below=1.5cm of VB] (B_VB) {
    $P(\text{win})=0.25$\\
    $P(\text{book})=0.25$\\
    $P(\text{run})=0.50$
  };

  \node[box, below=1.5cm of MD] (B_MD) {
    $P(\text{can})=1.0$
  };
  
  % Linee tratteggiate per emissioni
  \draw[dashed] (DT) -- (B_DT);
  \draw[dashed] (PRP) -- (B_PRP);
  \draw[dashed] (NN) -- (B_NN);
  \draw[dashed] (NNS) -- (B_NNS);
  \draw[dashed] (VBZ) -- (B_VBZ);
  \draw[dashed] (VBP) -- (B_VBP);
  \draw[dashed] (VB) -- (B_VB);
  \draw[dashed] (MD) -- (B_MD);
\end{tikzpicture}
\end{document}
```

#### Conclusione

Questo √® un semplice esempio pratico che mostra come costruire un HMM da un corpus annotato, calcolare tutte le probabilit√†, e disegnare il grafo corrispondente. Nella realt√† si lavora su tagset e vocabolari molto pi√π grandi, ma il concetto √® lo stesso.

## PoS Decoding

Nel contesto dei modelli **HMM**, il **decoding** √® il processo per determinare la sequenza pi√π probabile di stati nascosti (in questo caso, i PoS tag) dati una sequenza osservata di parole.

<br>

> **Decoding**: Dato in input un HMM $\lambda = (A, B)$ e una sequenza di osservazioni $O = o_1, o_2, \dots, o_T$, il compito √® trovare la sequenza di stati $Q = q_1 q_2 q_3 \dots q_T$ pi√π probabile.

Nel caso del **PoS tagging**, le **osservazioni** corrispondono alle parole, mentre gli **stati** rappresentano i corrispondenti PoS tag. L'obiettivo √® quindi assegnare ad ogni parola il PoS tag pi√π plausibile secondo il modello HMM.

### Algoritmo di Viterbi

Il **decoding** viene eseguito tramite l'**algoritmo di Viterbi**, che trova il percorso di stati pi√π probabile (la sequenza di tag PoS pi√π plausibile) che ha generato la sequenza osservata.

L'algoritmo lavora in tre fasi:

- **Inizializzazione**: calcola la probabilit√† iniziale per ciascuno stato, moltiplicando la probabilit√† iniziale $\pi_s$ per la probabilit√† di emissione della prima osservazione.
  
- **Ricorsione**: per ogni parola nella sequenza (dalla seconda in poi), si aggiorna la matrice delle probabilit√† di percorso considerando il massimo tra tutti i possibili stati precedenti.

- **Terminazione**: si seleziona il percorso con la probabilit√† totale pi√π alta.

> Output: `bestpath`, la sequenza pi√π probabile di stati (PoS tag), e `bestpathprob`, la sua probabilit√†.

$$
\begin{aligned}
\textbf{VITERBI}(O = o_1, o_2, \dots, o_T; \lambda = (A, B)) &\Rightarrow \text{best-path}, \text{path-prob} \\
\\
\textbf{Inizializzazione:} \quad &\text{crea una matrice } \textit{viterbi}[N, T]\\
\quad &\text{per ogni stato } s = 1 \dots N \\
&\quad \textit{viterbi}[s, 1] \leftarrow \pi_s \cdot b_s(o_1) \\
&\quad \textit{backpointer}[s, 1] \leftarrow 0 \\
\\
\textbf{Ricorsione:} \quad &\text{per ogni } t = 2 \dots T \\
&\quad \text{per ogni stato } s = 1 \dots N \\
&\quad \quad \textit{viterbi}[s, t] \leftarrow \max_{s'} \left( \textit{viterbi}[s', t-1] \cdot a_{s', s} \cdot b_s(o_t) \right) \\
&\quad \quad \textit{backpointer}[s, t] \leftarrow \mathop{\arg\max}\limits_{s'} \left( \textit{viterbi}[s', t-1] \cdot a_{s', s} \cdot b_s(o_t) \right) \\
\\
\textbf{Terminazione:} \quad &\text{bestpathprob} \leftarrow \max_{s=1}^N \left( \textit{viterbi}[s, T] \right) \\
&\text{bestpathpointer} \leftarrow \mathop{\arg\max}\limits_{s=1}^{N} \left( \textit{viterbi}[s, T] \right) \\
&\text{Ricostruzione del percorso usando } \textit{backpointer} \\
\end{aligned}
$$

**Spiegazione Intuitiva**

L'algoritmo di Viterbi si basa su un principio semplice ma potente: invece di considerare **tutti** i possibili percorsi attraverso la rete di stati (cosa computazionalmente proibitiva), calcola **ricorsivamente** il percorso pi√π probabile che porta a ciascuno stato in ogni istante di tempo. Cos√¨ facendo, sfrutta il principio di **ottimalit√†** della programmazione dinamica.

Ecco l'idea chiave:

- Se vogliamo sapere qual √® la sequenza di stati pi√π probabile che ha generato una sequenza di osservazioni, possiamo costruirla passo dopo passo, **tenendo traccia solo dei percorsi migliori** verso ciascuno stato.
- In ogni momento, per uno stato corrente $s$, si calcola la **probabilit√† massima di arrivare l√¨** da uno qualsiasi degli stati precedenti $s'$, **moltiplicando**:
  1. la probabilit√† del miglior percorso fino a $s'$ al tempo $t-1$
  2. la probabilit√† di transizione da $s'$ a $s$ ($a_{s', s}$)
  3. la probabilit√† di emissione dell'osservazione corrente da $s$ ($b_s(o_t)$)

Questo approccio si basa su un'importante assunzione del modello di Markov (HMM):

- La **probabilit√† di uno stato** dipende **solo** dallo stato precedente (Markoviano)
- L'**osservazione** dipende **solo** dallo stato attuale

**Perch√© funziona?**  
Perch√© grazie alla struttura a stati e alle probabilit√† condizionate dell‚ÄôHMM, possiamo decomporre un problema complesso (trovare il percorso globale ottimo) in tanti sottoproblemi pi√π semplici (trovare il miglior percorso fino a un certo stato in un certo istante), e riutilizzare le soluzioni ai sottoproblemi precedenti. Questo √® esattamente ci√≤ che fa la programmazione dinamica.

Infine, una volta costruita la matrice `viterbi`, usiamo `backpointer` per ricostruire **all‚Äôindietro** la sequenza ottimale degli stati, partendo dallo stato finale con la massima probabilit√†.

In sintesi:

- Non esplora tutti i percorsi possibili.
- Sfrutta solo i percorsi migliori a ogni passo.
- √à efficiente (tempo lineare nella lunghezza della sequenza).
- √à esatto (garantisce il percorso pi√π probabile).

### Applicazione dell'Algoritmo di Viterbi per la sequenza "we can run"

Questo documento illustra passo dopo passo l'applicazione dell'algoritmo di Viterbi per trovare la sequenza di tag POS (Part-Of-Speech) pi√π probabile per la frase "we can run". 

**Parametri di Input**
- **Sequenza di osservazioni**:  
  $$O = (o_1, o_2, o_3) = (\text{we},\, \text{can},\, \text{run})$$  
  Dove $T = 3$ √® la lunghezza della sequenza.

- **Insieme degli stati (tag POS)**:  
  $$Q = \{\text{DT}, \text{PRP}, \text{NN}, \text{NNS}, \text{MD}, \text{VBZ}, \text{VBP}, \text{VB}\}$$  
  Alcuni stati (VBZ, VBP, VB) hanno probabilit√† iniziale $\pi_s = 0$.

- **Parametri**:
  - $\pi_s$: Probabilit√† iniziali degli stati.
  - $A = [a]_{i,j}$: Matrice di transizione tra stati.
  - $B = b_i(o_t)$: Matrice di emissione (probabilit√† che uno stato $i$ emetta una parola $o_t$).

**1. Inizializzazione ($t=1$)**

Calcoliamo le probabilit√† $v[s,1]$ per tutti gli stati al primo passo temporale ($t=1$), usando la formula:  
$$v[s,1] = \pi_s \cdot b_s(\text{we})$$

**Spiegazione**:
- $v[s,1]$: Probabilit√† del percorso pi√π probabile che termina nello stato $s$ al tempo $t=1$.
- Solo gli stati con $\pi_s > 0$ **e** $b_s(\text{we}) > 0$ contribuiscono.  

| Stato $s$ | $\pi_s$      | $b_s(\text{we})$ | $v[s,1]$          | Note                                  |
|-------------|----------------|---------------------|---------------------|---------------------------------------|
| DT          | $4/9 \approx 0.444$ | 0                  | $0$              | Emissione nulla per "we"              |
| PRP     | $1/9 \approx 0.111$ | $0.50$            | $\frac{1}{18} \approx 0.0556$ | Unico stato con probabilit√† non nulla |
| NN          | $1/9$        | 0                  | $0$              | Emissione nulla                      |
| NNS         | $2/9$        | 0                  | $0$              | Emissione nulla                      |
| MD          | $1/9$        | 0                  | $0$              | Emissione nulla                      |
| VBZ         | $0$              | $0$                  | $0$              | Probabilit√† iniziale nulla           |
| VBP         | $0$              | $0$                  | $0$              | Probabilit√† iniziale nulla           |
| VB          | $0$              | $0$                  | $0$              | Probabilit√† iniziale nulla           |

**Chiarimenti**:
- Lo stato PRP √® l'unico attivo a $t=1$ perch√© ha sia $\pi_s > 0$ che $b_s(\text{we}) > 0$.
- I valori di $\pi_s$ per VBZ, VBP, VB sono zero (non presenti nel training data iniziale).

### 2. Fase Ricorsiva

#### Passo $t=2$ (osservazione: "can")

**Emissioni rilevanti**:  
- $b_{\text{NN}}(\text{can}) = 0.25$  
- $b_{\text{MD}}(\text{can}) = 1.00$  

Calcoliamo $v[s,2]$ solo per NN e MD (unici stati con emissione non nulla):

1. **Per lo stato NN**:  
   $$v[\text{NN},2] = \max_{s'} \left( v[s',1] \cdot a_{s',\text{NN}} \cdot 0.25 \right)$$  
   - $s'$ pu√≤ essere solo PRP (unico stato con $v[s',1] > 0$).  
   - $a_{\text{PRP},\text{NN}} = 0$ (transizione PRP‚ÜíNN non consentita).  
   - Risultato: $v[\text{NN},2] = 0.0556 \cdot 0 \cdot 0.25 = 0$.

2. **Per lo stato MD**:  
   $$v[\text{MD},2] = \max_{s'} \left( v[s',1] \cdot a_{s',\text{MD}} \cdot 1.00 \right)$$  
   - $a_{\text{PRP},\text{MD}} = 0.5$ (transizione PRP‚ÜíMD consentita).  
   - Risultato: $v[\text{MD},2] = 0.0556 \cdot 0.5 \cdot 1 = 0.0278$.  
   - Backpointer: $bp[\text{MD},2] = \text{PRP}$ (stato precedente ottimale).

| Stato $s$ | $v[s,2]$       | $bp[s, 2]$   | Note                          |
|-------------|------------------|------|-------------------------------|
| MD          | $\frac{1}{36} \approx 0.0278$ | PRP  | Unico stato attivo a $t=2$ |
| NN          | $0$            | ‚Äî    | Probabilit√† nulla            |
| Altri       | $0$            | ‚Äî    | Emissione nulla              |

#### Passo $t=3$ (osservazione: "run")

**Emissioni rilevanti**:  
- $b_{\text{VB}}(\text{run}) = 0.50$ (solo VB emette "run").  

Calcoliamo $v[\text{VB},3]$:  
$$v[\text{VB},3] = \max_{s'} \left( v[s',2] \cdot a_{s',\text{VB}} \cdot 0.50 \right)$$  

- $s'$ pu√≤ essere solo MD (unico stato con $v[s',2] > 0$).  
- $a_{\text{MD},\text{VB}} = \frac{2}{3}$ (transizione MD‚ÜíVB consentita).  
- Risultato:  
  $$v[\text{VB},3] = 0.0278 \cdot \frac{2}{3} \cdot 0.5 = \frac{1}{108} \approx 0.00926$$  
- Backpointer: $bp[\text{VB},3] = \text{MD}$.

| Stato $s$ | $v[s,3]$         | $bp[s, 3]$   | Note                          |
|-------------|--------------------|------|-------------------------------|
| VB          | $\frac{1}{108} \approx 0.00926$ | MD  | Unico stato attivo a $t=3$ |
| Altri       | $0$              | ‚Äî    | Emissione nulla              |

Alla fine, abbiamo la tabella di valori ottimali:

| Stato   | $o_1$="we" (t=1)      | $o_2$="can" (t=2)       | $o_3$="run" (t=3)        |
|---------|-----------------------|-------------------------|---------------------------|
| DT      | $0$                   | $0$                     | $0$                       |
| PRP     | $\frac{1}{18} \approx 0.0556$ | $0$                     | $0$                       |
| NN      | $0$                   | $0$                     | $0$                       |
| NNS     | $0$                   | $0$                     | $0$                       |
| MD      | $0$                   | $\frac{1}{36} \approx 0.0278$ | $0$                       |
| VBZ     | $0$                   | $0$                     | $0$                       |
| VBP     | $0$                   | $0$                     | $0$                       |
| VB      | $0$                   | $0$                     | $\frac{1}{108} \approx 0.00926$ |


e la tabella di backpointers:

| Stato   | $o_1$="we" (t=1) | $o_2$="can" (t=2) | $o_3$="run" (t=3) |
|---------|-------------------|-------------------|-------------------|
| DT      | $0$              | ‚Äî                 | ‚Äî                 |
| PRP     | $0$              | ‚Äî                 | ‚Äî                 |
| NN      | $0$              | ‚Äî                 | ‚Äî                 |
| NNS     | $0$              | ‚Äî                 | ‚Äî                 |
| MD      | $0$              | **PRP**           | ‚Äî                 |
| VBZ     | $0$              | ‚Äî                 | ‚Äî                 |
| VBP     | $0$              | ‚Äî                 | ‚Äî                 |
| VB      | $0$              | ‚Äî                 | **MD**            |

#### 3. Terminazione e Ricostruzione del Percorso

1. **Terminazione**:  
   - Troviamo lo stato finale ottimale:  
     $$\text{bestpathprob} = \max_{s} v[s,T] = \max_{s} v[s,3] = v[\text{VB},3] \approx 0.00926$$  
   - Stato finale: $s^* = \text{VB}$.

2. **Ricostruzione all'indietro** (backtracking):  
   - $\hat{s}_3 = \text{VB}$  
   - $\hat{s}_2 = bp[\text{VB},3] = \text{MD}$  
   - $\hat{s}_1 = bp[\text{MD},2] = \text{PRP}$  

**Sequenza ottimale**:  
$$(\text{PRP},\, \text{MD},\, \text{VB}) \quad \text{con probabilit√† } \approx 0.926\%$$  

**Interpretazione linguistica**:  
- **PRP**: Pronome personale ("we").  
- **MD**: Verbo modale ("can").  
- **VB**: Verbo base ("run").

## Conclusione: HMM e Viterbi nel PoS Tagging

### üîç Punti Chiave
1. **Modellazione Contestuale**: Gli HMM catturano le dipendenze sequenziali tra i tag attraverso le probabilit√† di transizione  
2. **Efficienza Computazionale**: L'algoritmo di Viterbi riduce la complessit√† da esponenziale a lineare grazie alla programmazione dinamica  
3. **Addestramento Data-Driven**: Le probabilit√† sono stimate direttamente da corpora annotati, garantendo adattabilit√† a diversi domini linguistici  

### üõë Limiti Pratici
- **Sparsit√† dei Dati**: Transizioni/emissioni non osservate nei dati di training ricevono probabilit√† zero (problema dello smoothing)  
- **Contesto Limitato**: L'assunzione markoviana di primo ordine ignora dipendenze a lungo raggio  
- **Ambiguity Resolution**: Difficolt√† con parole polisemiche che richiederebbero contesto semantico  

#### üí° Soluzioni Ibride Moderne
1. **Integrazione con Reti Neurali**  
   - Usare HMM per la struttura sequenziale + Embedding neurali per rappresentazioni contestuali  
   - Esempio: **BiLSTM-CRF** combinano la potenza delle reti ricorrenti con modelli grafici  

2. **Transformer-Based Taggers**  
   - Modelli come BERT sfruttano l'attenzione globale per catturare dipendenze complesse  
   - Accuracy >98% sul Penn Treebank contro il 95-97% degli HMM classici  

3. **Active Learning**  
   - Ridurre la dipendenza da grandi corpora annotati attraverso annotazioni mirate  
   - Particolarmente utile per lingue low-resource o domini specialistici  

#### üìö Riferimenti

- [Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)
- [Jurafsky and Martin - Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)